{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6a044a19-cbf5-459d-ad33-15f3115f477f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "from numpy import argmax\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "from transformers import AutoModelForTokenClassification\n",
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fca5aa-2c41-45c8-a600-8866bc41a7d0",
   "metadata": {},
   "source": [
    "# Load DatasetDict-s for Few-Shot Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "472fee42-8b69-4823-ad21-078faa642459",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd_dst_paths = [\n",
    "                         '../dataset/scnd_thrd_train_frst_test_dd.pkl', \n",
    "                         '../dataset/frst_thrd_train_scnd_test_dd.pkl', \n",
    "                         '../dataset/frst_scnd_train_thrd_test_dd.pkl',\n",
    "                         '../dataset/all_papers_train_dd.pkl'\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0ee1cc-0965-4231-958c-122683b7f379",
   "metadata": {},
   "source": [
    "## Train: 2,3\n",
    "## Test: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "58ec2876-362e-4d80-8d5f-f9a238198690",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec55186-986f-4dfb-b451-44499e1134de",
   "metadata": {},
   "source": [
    "## Train: 1,3\n",
    "## Test: 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7603af4b-bd76-46e1-ad53-f57115ca4bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6a0aee-418b-41da-b878-6f33a93b510a",
   "metadata": {},
   "source": [
    "## Train: 1,2\n",
    "## Test: 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "71667223-45ad-49a6-b372-01178a752db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (dd_dst_paths[2], 'rb') as file:\n",
    "    frst_scnd_train_thrd_test_dd = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f37d1ec-9f91-446d-a108-3d1993167aaf",
   "metadata": {},
   "source": [
    "## Check the loaded DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f86d8c14-766d-4f6a-b410-ab81fb2bbed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['paper', 'tokens', 'labels', 'tags'],\n",
       "        num_rows: 1117\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['paper', 'tokens', 'labels', 'tags'],\n",
       "        num_rows: 320\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frst_scnd_train_thrd_test_dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "67a8a836-d9df-4660-bef9-b6fea4498c1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'activation',\n",
       " 'functions',\n",
       " 'of',\n",
       " 'the',\n",
       " 'LSTM',\n",
       " 'layers',\n",
       " 'were',\n",
       " 'tanh',\n",
       " '12',\n",
       " 'in',\n",
       " 'the',\n",
       " 'proposed',\n",
       " 'architecture',\n",
       " '.']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frst_scnd_train_thrd_test_dd['test'][9]['tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "be3cbf2d-af7b-4446-a76c-433a35204207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \n",
      "\n",
      "['5.4', 'Ensemble', 'of', 'trees', 'using', 'LPBoost', 'Boosting', 'is', 'another', 'ensemble', 'method', 'used', 'to', 'enhance', 'the', 'performance', 'of', 'weak', 'learners', 'i.e.', 'trees', '.'] \n",
      "\n",
      "[0, 1, 2, 2, 0, 1, 2, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "\n",
      "['O', 'B-ML', 'I-ML', 'I-ML', 'O', 'B-ML', 'I-ML', 'O', 'O', 'B-ML', 'I-ML', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for feature in frst_scnd_train_thrd_test_dd['train'].features:\n",
    "    print(frst_scnd_train_thrd_test_dd['train'][199][feature], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7d2d9ce3-92f5-42cd-b012-0cbde23f3fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 \n",
      "\n",
      "['The', 'input', 'goes', 'through', '122', 'two', 'LSTM', 'layers', 'and', 'then', 'a', 'ﬂatten', 'layer', 'is', 'attached', 'to', 'it', 'where', 'the', 'second', 'LSTM', '123', 'layer', 'was', 'bidirectional', 'layer', '.'] \n",
      "\n",
      "[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0] \n",
      "\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-ML', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ML', 'O', 'O', 'O', 'O', 'O', 'O'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for feature in frst_scnd_train_thrd_test_dd['test'].features:\n",
    "    print(frst_scnd_train_thrd_test_dd['test'][100][feature], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0ee944-f80e-4a52-aec0-0cc54d279f94",
   "metadata": {},
   "source": [
    "# Match up words with their NER tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "17a3a84b-6db2-4f4f-a09c-aef64ef0e213",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = ['O', 'B-ML', 'I-ML']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2832b75d-2f15-424f-b593-ef6f8fa4f9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.4 Ensemble of   trees using LPBoost Boosting is another ensemble method used to enhance the performance of weak learners i.e. trees . \n",
      "O   B-ML     I-ML I-ML  O     B-ML    I-ML     O  O       B-ML     I-ML   O    O  O       O   O           O  O    O        O    O     O \n"
     ]
    }
   ],
   "source": [
    "words = frst_scnd_train_thrd_test_dd[\"train\"][199][\"tokens\"]\n",
    "labels = frst_scnd_train_thrd_test_dd[\"train\"][199][\"labels\"]\n",
    "line1 = \"\"\n",
    "line2 = \"\"\n",
    "for word, label in zip(words, labels):\n",
    "    full_label = label_names[label]\n",
    "    max_length = max(len(word), len(full_label))\n",
    "    line1 += word + \" \" * (max_length - len(word) + 1)\n",
    "    line2 += full_label + \" \" * (max_length - len(full_label) + 1)\n",
    "\n",
    "print(line1)\n",
    "print(line2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480d2d34-e49a-44ad-a500-48a18829a29b",
   "metadata": {},
   "source": [
    "# Check the Tokenizer for BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c9bbaaab-15d7-4b35-8bc7-c59cff150b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_checkpoint = \"bert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "tokenizer.is_fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "642e3e41-dd84-416c-9784-009ebf856c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '5', '.', '4', 'Ensemble', 'of', 'trees', 'using', 'LP', '##B', '##oos', '##t', 'Bo', '##ost', '##ing', 'is', 'another', 'ensemble', 'method', 'used', 'to', 'enhance', 'the', 'performance', 'of', 'weak', 'learn', '##ers', 'i', '.', 'e', '.', 'trees', '.', '[SEP]'] \n",
      "\n",
      "dict_items([('input_ids', [101, 126, 119, 125, 12618, 1104, 2863, 1606, 6400, 2064, 26459, 1204, 9326, 15540, 1158, 1110, 1330, 9525, 3442, 1215, 1106, 11778, 1103, 2099, 1104, 4780, 3858, 1468, 178, 119, 174, 119, 2863, 119, 102]), ('token_type_ids', [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), ('attention_mask', [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])]) \n",
      "\n",
      "[101, 126, 119, 125, 12618, 1104, 2863, 1606, 6400, 2064, 26459, 1204, 9326, 15540, 1158, 1110, 1330, 9525, 3442, 1215, 1106, 11778, 1103, 2099, 1104, 4780, 3858, 1468, 178, 119, 174, 119, 2863, 119, 102] \n",
      "\n",
      "[None, 0, 0, 0, 1, 2, 3, 4, 5, 5, 5, 5, 6, 6, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 18, 19, 19, 19, 19, 20, 21, None] \n",
      "\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(frst_scnd_train_thrd_test_dd['train'][199]['tokens'], is_split_into_words=True)\n",
    "\n",
    "print(inputs.tokens(), '\\n')\n",
    "print(inputs.items(), '\\n')\n",
    "print(inputs['input_ids'], '\\n')\n",
    "print(inputs.word_ids(), '\\n')\n",
    "print(tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2734043-72c1-4cf7-a114-a2bd391f7b56",
   "metadata": {},
   "source": [
    "### The tokenizer works fine ✔"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89968c10-b88c-4ee1-b512-30bda3e29dbb",
   "metadata": {},
   "source": [
    "# Align sequences after the BERT-tokenization\n",
    "\n",
    "For instance, we had the following sequence: ['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']\n",
    "\r\n",
    "The same sequence after tokenization: ['[CLS]', 'EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'la', '##mb', '.', '[SEP]'\n",
    "\n",
    "For the latter we need to add ids, labels and tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fbbb0bb3-5dd6-4bfa-af26-26da8fc93dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_labels_with_tokens(labels, word_ids):\n",
    "    \"\"\"Assign -100 to None and the same label to a token if it was split\"\"\"\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    for word_id in word_ids:\n",
    "        if word_id != current_word:\n",
    "            # Start of a new word!\n",
    "            current_word = word_id\n",
    "            label = -100 if word_id is None else labels[word_id] # by default -100 is an index that is ignored in the loss function (cross entropy)\n",
    "            new_labels.append(label)\n",
    "        elif word_id is None:\n",
    "            # Special token\n",
    "            new_labels.append(-100)\n",
    "        else:\n",
    "            # Same word as previous token\n",
    "            label = labels[word_id]\n",
    "            # If the label is B-XXX we change it to I-XXX\n",
    "            if label % 2 == 1:\n",
    "                label += 1\n",
    "            new_labels.append(label)\n",
    "\n",
    "    return new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "82ee6bea-6417-4f7d-a5c6-50c45cb54f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_labels: [0, 1, 2, 2, 0, 1, 2, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "\n",
      "word_ids after tokenization (order in the seq): [None, 0, 0, 0, 1, 2, 3, 4, 5, 5, 5, 5, 6, 6, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 18, 19, 19, 19, 19, 20, 21, None] \n",
      "\n",
      "Initial sample:\n",
      "['5.4', 'Ensemble', 'of', 'trees', 'using', 'LPBoost', 'Boosting', 'is', 'another', 'ensemble', 'method', 'used', 'to', 'enhance', 'the', 'performance', 'of', 'weak', 'learners', 'i.e.', 'trees', '.']\n",
      "\n",
      "Its NER-representation:\n",
      "[0, 1, 2, 2, 0, 1, 2, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "\n",
      "________________________________________________\n",
      "\n",
      "The same sample after tokenization:\n",
      "['[CLS]', '5', '.', '4', 'Ensemble', 'of', 'trees', 'using', 'LP', '##B', '##oos', '##t', 'Bo', '##ost', '##ing', 'is', 'another', 'ensemble', 'method', 'used', 'to', 'enhance', 'the', 'performance', 'of', 'weak', 'learn', '##ers', 'i', '.', 'e', '.', 'trees', '.', '[SEP]']\n",
      "\n",
      "Its NER-representation:\n",
      "[-100, 0, 0, 0, 1, 2, 2, 0, 1, 2, 2, 2, 2, 2, 2, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(frst_scnd_train_thrd_test_dd['train'][199]['tokens'], is_split_into_words=True)\n",
    "labels = frst_scnd_train_thrd_test_dd['train'][199]['labels']\n",
    "print(f\"ner_labels: {labels} \\n\")\n",
    "word_ids = inputs.word_ids()\n",
    "print(f\"word_ids after tokenization (order in the seq): {word_ids} \\n\")\n",
    "\n",
    "# initial sequence\n",
    "print(f\"Initial sample:\\n{frst_scnd_train_thrd_test_dd['train'][199]['tokens']}\\n\\nIts NER-representation:\\n{labels} \\n\")\n",
    "print(\"________________________________________________\\n\")\n",
    "# sequence after tokenization routine for BERT\n",
    "print(f\"The same sample after tokenization:\\n{tokenizer(frst_scnd_train_thrd_test_dd['train'][199]['tokens'], is_split_into_words=True).tokens()}\\n\\nIts NER-representation:\\n{align_labels_with_tokens(labels, word_ids)} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d706919f-d587-403d-b9d0-a3fce67678b8",
   "metadata": {},
   "source": [
    "## Tokenize and align the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1e9475b6-f585-4d11-8b8e-d4d0fe12c218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples['tokens'], truncation=True, is_split_into_words=True\n",
    "    )\n",
    "    all_labels = examples['labels']\n",
    "    new_labels = []\n",
    "    for i, labels in enumerate(all_labels):\n",
    "        word_ids = tokenized_inputs.word_ids(i)\n",
    "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
    "\n",
    "    tokenized_inputs['labels'] = new_labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "257cb0c8-2249-467c-bbf4-4733f7a49362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53cbe0c39f3c457eb1c00b4d90a707b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1117 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20b5270bde454d84a4320893eea8b304",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/320 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = frst_scnd_train_thrd_test_dd.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    remove_columns=frst_scnd_train_thrd_test_dd['train'].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cd2d96f3-020a-4727-b18c-ce3ff24bc355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': [-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100],\n",
       " 'input_ids': [101,\n",
       "  1188,\n",
       "  2237,\n",
       "  2515,\n",
       "  1103,\n",
       "  24431,\n",
       "  10008,\n",
       "  1155,\n",
       "  1103,\n",
       "  11934,\n",
       "  1105,\n",
       "  1147,\n",
       "  19218,\n",
       "  119,\n",
       "  102],\n",
       " 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets['train'][120]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43aa3516-8492-4af3-9eea-9233225418e8",
   "metadata": {},
   "source": [
    "**X = input_ids**\n",
    "\n",
    "**y_true = labels**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff4e401-1f3b-4c87-97c2-9171c7a73704",
   "metadata": {},
   "source": [
    "### Our training data is ready to be fitted to BERT ✔"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97df4a2-bfc5-4222-a17d-d547d8974a29",
   "metadata": {},
   "source": [
    "# Collate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9d0c774d-3408-4609-8ff8-a3c2e665b74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8c50d513-0477-4bff-9195-66deca5c4ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-100,    0,    0,    0,    1,    2,    2,    0,    1,    2,    2,    2,\n",
       "            2,    2,    2,    0,    0,    1,    2,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0, -100, -100,\n",
       "         -100, -100, -100],\n",
       "        [-100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    1,    2,    0,    0,    0,    0,    0,\n",
       "            0,    0, -100],\n",
       "        [-100,    0,    0,    0,    0,    0,    1,    2,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = data_collator([tokenized_datasets['train'][i] for i in range(199, 202)])\n",
    "batch[\"labels\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57993556-166c-46d7-8462-4e7a855cbf00",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d947526a-31aa-4446-9699-06baddd1a48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load('seqeval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d09ba8ac-9b93-484a-ae69-3e35aed0ae26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'B-ML',\n",
       " 'I-ML',\n",
       " 'I-ML',\n",
       " 'O',\n",
       " 'B-ML',\n",
       " 'I-ML',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-ML',\n",
       " 'I-ML',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = frst_scnd_train_thrd_test_dd['train'][199]['labels']\n",
    "labels = [label_names[i] for i in labels]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "18fcc78e-cc59-46bd-a714-0d85e79ab3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'B-ML', 'I-ML', 'I-ML', 'O', 'B-ML', 'I-ML', 'O', 'O', 'B-ML', 'I-ML', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'B-ML', 'I-ML', 'O', 'O', 'O', 'I-ML', 'O', 'O', 'B-ML', 'I-ML', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ML': {'precision': 0.3333333333333333,\n",
       "  'recall': 0.3333333333333333,\n",
       "  'f1': 0.3333333333333333,\n",
       "  'number': 3},\n",
       " 'overall_precision': 0.3333333333333333,\n",
       " 'overall_recall': 0.3333333333333333,\n",
       " 'overall_f1': 0.3333333333333333,\n",
       " 'overall_accuracy': 0.9090909090909091}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = labels.copy()\n",
    "print(predictions)\n",
    "for idx, label in enumerate(predictions):\n",
    "    if idx == 3 or idx == 5:\n",
    "        predictions[idx] = 'O'\n",
    "print(predictions)\n",
    "metric.compute(predictions=[predictions], references=[labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c92098-8fd4-4c89-b89e-568987279054",
   "metadata": {},
   "source": [
    "# The following function will be applied in Trainer down below to compute metrics for the whole validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "75ab94d7-cd32-49f9-aefc-43b996afa53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = argmax(logits, axis=-1)\n",
    "\n",
    "    # Remove ignored index (special tokens) and convert to labels\n",
    "    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n",
    "    true_predictions = [\n",
    "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": all_metrics[\"overall_precision\"],\n",
    "        \"recall\": all_metrics[\"overall_recall\"],\n",
    "        \"f1\": all_metrics[\"overall_f1\"],\n",
    "        \"accuracy\": all_metrics[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c837bbad-8811-4293-89ed-8724dc9be841",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {i: label for i, label in enumerate(label_names)}\n",
    "label2id = {v: k for k, v in id2label.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3267de1-fafe-46ec-9401-d70f08c63c1e",
   "metadata": {},
   "source": [
    "# Import BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1c1b53e6-26b9-4828-8301-8077543c6cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_checkpoint, \n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ecda193c-d0c2-4618-8099-666cdf6d7c11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.num_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ff5eb9-87e7-48f4-a1bd-0de804a88a1c",
   "metadata": {},
   "source": [
    "# Set train arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "38769154-37a0-4a44-8b10-d3c7a3da73d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    \"bert-finetuned-ner\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6fca54-fc79-42e7-9606-fdf531045b13",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "62894233-dafb-408c-934c-4be9b81be247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='700' max='700' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [700/700 42:17, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.105906</td>\n",
       "      <td>0.581633</td>\n",
       "      <td>0.522936</td>\n",
       "      <td>0.550725</td>\n",
       "      <td>0.968709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.096057</td>\n",
       "      <td>0.601770</td>\n",
       "      <td>0.623853</td>\n",
       "      <td>0.612613</td>\n",
       "      <td>0.971941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.133957</td>\n",
       "      <td>0.563636</td>\n",
       "      <td>0.568807</td>\n",
       "      <td>0.566210</td>\n",
       "      <td>0.972381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.035600</td>\n",
       "      <td>0.139458</td>\n",
       "      <td>0.534483</td>\n",
       "      <td>0.568807</td>\n",
       "      <td>0.551111</td>\n",
       "      <td>0.970912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.035600</td>\n",
       "      <td>0.143096</td>\n",
       "      <td>0.556522</td>\n",
       "      <td>0.587156</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.972234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime: 2540.6725029945374\n"
     ]
    }
   ],
   "source": [
    "start = time.time() \n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['test'],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "trainer.train()\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(f'Runtime: {end - start}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef546d5-adb9-4af4-85f6-cb60fa4ab30c",
   "metadata": {},
   "source": [
    "# Test the seqeval package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1e1bb30-7bad-48ee-b340-223931e1c84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        MISC       1.00      1.00      1.00         1\n",
      "         PER       1.00      1.00      1.00         1\n",
      "\n",
      "   micro avg       1.00      1.00      1.00         2\n",
      "   macro avg       1.00      1.00      1.00         2\n",
      "weighted avg       1.00      1.00      1.00         2\n",
      "\n",
      "Accuracy: 0.9\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import accuracy_score\n",
    "from seqeval.metrics import classification_report\n",
    "from seqeval.metrics import f1_score\n",
    "y_true = [['O', 'O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'O'], ['B-PER', 'I-PER', 'O']]\n",
    "y_pred = [['O', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'O'], ['B-PER', 'I-PER', 'O']]\n",
    "print(classification_report(y_true, y_pred))\n",
    "print(f\"Accuracy: {accuracy_score(y_true, y_pred)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
